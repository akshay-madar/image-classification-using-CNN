{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Resources:\n",
    "1) https://pdfs.semanticscholar.org/450c/a19932fcef1ca6d0442cbf52fec38fb9d1e5.pdf <br><br>\n",
    "2) https://arxiv.org/abs/1609.04112<br><br>\n",
    "3) https://arxiv.org/abs/1502.01852<br><br>\n",
    "4) http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf<br><br>\n",
    "5) https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html<br><br>\n",
    "6) https://www.youtube.com/watch?v=PHP8beSz5o4<br><br>\n",
    "7) https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/<br><br>\n",
    "8) https://peterroelants.github.io/posts/neural-network-implementation-part01/<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switching keras bankend from theano to tensorflow\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import keras \n",
    "keras.backend.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iamak\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer parameters:\n",
    "feature detectors = 32 <br>\n",
    "their size = 3x3<br>\n",
    "input_shape = 64x64 pixels, 3 rgb image<br>\n",
    "rectifier function to add non-linearity is 'relu'\n",
    "\n",
    "### final layer\n",
    "activation function = 'sigmoid' since binary classification\n",
    "\n",
    "Use 'softmax' for multi-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iamak\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iamak\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iamak\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu')) \n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu')) # pooled feature maps from previous layers, so no nned to add input_shape\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iamak\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iamak\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iamak\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation/Pre-processing\n",
    "\n",
    "Image augmentation is used to create more images for the model to learn by rotating, etc. randomly. The model needs to learn pixel patterns from a large number of images. It also prevents overfitting.\n",
    "\n",
    "#### Keras documentation: https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\iamak\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 1577s 197ms/step - loss: 0.3609 - acc: 0.8302 - val_loss: 0.5780 - val_acc: 0.8045\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 1489s 186ms/step - loss: 0.1018 - acc: 0.9616 - val_loss: 0.9531 - val_acc: 0.8022\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 2399s 300ms/step - loss: 0.0517 - acc: 0.9815 - val_loss: 1.1148 - val_acc: 0.8048\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 11976s 1s/step - loss: 0.0380 - acc: 0.9870 - val_loss: 1.2684 - val_acc: 0.8102\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 25216s 3s/step - loss: 0.0297 - acc: 0.9899 - val_loss: 1.2113 - val_acc: 0.8061\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 3364s 420ms/step - loss: 0.0258 - acc: 0.9914 - val_loss: 1.3842 - val_acc: 0.8045\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 2964s 370ms/step - loss: 0.0219 - acc: 0.9925 - val_loss: 1.4207 - val_acc: 0.8022\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1565s 196ms/step - loss: 0.0197 - acc: 0.9935 - val_loss: 1.3848 - val_acc: 0.8030\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 1541s 193ms/step - loss: 0.0179 - acc: 0.9942 - val_loss: 1.4407 - val_acc: 0.8025\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1774s 222ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 1.4523 - val_acc: 0.8081\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 1790s 224ms/step - loss: 0.0147 - acc: 0.9952 - val_loss: 1.5127 - val_acc: 0.8065\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 1577s 197ms/step - loss: 0.0142 - acc: 0.9957 - val_loss: 1.6367 - val_acc: 0.7931\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 1580s 197ms/step - loss: 0.0127 - acc: 0.9962 - val_loss: 1.5764 - val_acc: 0.8010\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 1614s 202ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 1.6267 - val_acc: 0.8007\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 1609s 201ms/step - loss: 0.0116 - acc: 0.9963 - val_loss: 1.6013 - val_acc: 0.8031\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 7197s 900ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 1.9217 - val_acc: 0.7840\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 7878s 985ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 1.7990 - val_acc: 0.7819\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 3311s 414ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 1.5835 - val_acc: 0.8013\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 3716s 465ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 1.5659 - val_acc: 0.8155\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 1784s 223ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 1.6846 - val_acc: 0.7966\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 2010s 251ms/step - loss: 0.0088 - acc: 0.9973 - val_loss: 1.5934 - val_acc: 0.8036\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 35684s 4s/step - loss: 0.0081 - acc: 0.9974 - val_loss: 1.5966 - val_acc: 0.8136\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 3191s 399ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 1.8147 - val_acc: 0.8039\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 3160s 395ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 1.7099 - val_acc: 0.8023\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 2597s 325ms/step - loss: 0.0075 - acc: 0.9979 - val_loss: 1.8678 - val_acc: 0.8032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1866fbfcfc8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, # pixel value between 0 and 1\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64), # image dimensions\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary') # 2 classes - cat and dog\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000, # number of images in training set\n",
    "                         epochs = 25, \n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving accuracy\n",
    "\n",
    "1) more data <br>\n",
    "2) adding more convolution layers<br>\n",
    "3) increasing target_size to capture more pixels (gpu recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
